# Structured TRTs

Sistema para extraÃ§Ã£o estruturada de dados de sentenÃ§as trabalhistas usando LLMs (Large Language Models).

## ğŸ“‹ PrÃ©-requisitos

- Python 3.11 ou superior
- [uv](https://docs.astral.sh/uv/) - Gerenciador de pacotes Python ultrarrÃ¡pido
- VS Code ou Cursor IDE
- Chaves de API para os modelos que deseja usar (OpenAI, Google Gemini, Groq)

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Instalar uv

Se ainda nÃ£o tem o uv instalado:

**Windows (PowerShell):**

```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

**macOS/Linux:**

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### 2. Clonar e configurar o projeto

```bash
# Clone o repositÃ³rio
git clone https://github.com/jtrecenti/structured_trts
cd structured_trts

# Sincronizar dependÃªncias com uv
uv sync

# Ativar o ambiente virtual
# No Windows:
.venv\Scripts\activate
# No macOS/Linux:
source .venv/bin/activate
```

### 3. Configurar variÃ¡veis de ambiente

Crie um arquivo `.env` na raiz do projeto:

```bash
# Copie o template (se existir) ou crie um novo
cp .env.example .env  # ou crie manualmente
```

Adicione suas chaves de API no arquivo `.env`:

```env
# OpenAI
OPENAI_API_KEY=sua_chave_openai_aqui

# Google Gemini
GOOGLE_API_KEY=sua_chave_google_aqui

# Groq
GROQ_API_KEY=sua_chave_groq_aqui
```

## ğŸ”§ ConfiguraÃ§Ã£o no VS Code/Cursor

### 1. Abrir o projeto

```bash
# Para VS Code
code .

# Para Cursor
cursor .
```

### 2. Selecionar o interpretador Python

1. Abra a paleta de comandos (`Ctrl+Shift+P` / `Cmd+Shift+P`)
2. Digite "Python: Select Interpreter"
3. Selecione o interpretador do ambiente virtual: `.venv/bin/python` (Linux/macOS) ou `.venv\Scripts\python.exe` (Windows)

### 3. ExtensÃµes recomendadas

Instale as seguintes extensÃµes no VS Code/Cursor:

- **Python** - Suporte completo para Python
- **Jupyter** - Para executar notebooks `.qmd`
- **Quarto** - Suporte para arquivos Quarto
- **Python Docstring Generator** - GeraÃ§Ã£o automÃ¡tica de docstrings

### 4. ConfiguraÃ§Ã£o do workspace (opcional)

Crie `.vscode/settings.json`:

```json
{
    "python.defaultInterpreterPath": "./.venv/bin/python",
    "python.terminal.activateEnvironment": true,
    "python.linting.enabled": true,
    "python.linting.pylintEnabled": true,
    "jupyter.notebookFileRoot": "${workspaceFolder}",
    "files.associations": {
        "*.qmd": "quarto"
    }
}
```

## ğŸ“Š Estrutura do Projeto

```text
structured_trts/
â”œâ”€â”€ src/structured_trts/     # CÃ³digo principal
â”‚   â”œâ”€â”€ extract.py          # MÃ³dulo de extraÃ§Ã£o com LLMs
â”‚   â””â”€â”€ utils.py            # UtilitÃ¡rios
â”œâ”€â”€ notebooks/              # Notebooks de anÃ¡lise
â”‚   â”œâ”€â”€ 0-read.qmd         # Leitura de dados
â”‚   â”œâ”€â”€ 1-extract-loop.qmd # Loop de extraÃ§Ã£o
â”‚   â””â”€â”€ 2-explore.qmd      # ExploraÃ§Ã£o de resultados
â”œâ”€â”€ prompts/               # Templates de prompts
â”‚   â””â”€â”€ prompt.md         # Prompt principal para extraÃ§Ã£o
â”œâ”€â”€ data/                 # Dados (criado automaticamente)
â”œâ”€â”€ pyproject.toml       # ConfiguraÃ§Ã£o do projeto
â”œâ”€â”€ uv.lock             # Lock file do uv
â””â”€â”€ README.md           # Este arquivo
```

### Workflow tÃ­pico

1. **Leitura de dados** (`0-read.qmd`):
   - Carrega e processa os textos
   - Calcula tokens e filtra por tamanho

2. **ExtraÃ§Ã£o estruturada** (`1-extract-loop.qmd`):
   - Configura modelos LLM
   - Executa extraÃ§Ã£o em lote
   - Salva resultados

3. **ExploraÃ§Ã£o** (`2-explore.qmd`):
   - Analisa resultados
   - Gera visualizaÃ§Ãµes
   - Calcula mÃ©tricas de performance

### Modelos utilizados

O sistema utiliza os seguintes modelos:

- **OpenAI**: GPT-4.1, GPT-4.1-mini, GPT-4.1-nano
- **Google**: Gemini 2.5 Pro, Gemini 2.5 Flash  
- **Groq**: Llama 4, GPT OSS, Kimi K2

Configure as chaves de API correspondentes no arquivo `.env`.

## ğŸ” Exemplo de uso rÃ¡pido

```python
from structured_trts.extract import extract_with_chatlas, load_prompt

# Carregar prompt
prompt = load_prompt("prompts/prompt.md")

# Extrair dados de um texto
text = "Sua sentenÃ§a trabalhista aqui..."
result = extract_with_chatlas(text, prompt, "gpt-4.1-mini")

if result.success:
    print(result.extracted_data)
else:
    print(f"Erro: {result.error_message}")
```

## ğŸ› ï¸ Comandos Ãºteis com uv

```bash
# Sincronizar dependÃªncias
uv sync

# Adicionar nova dependÃªncia
uv add nome-do-pacote

# Remover dependÃªncia
uv remove nome-do-pacote

# Executar script no ambiente
uv run python script.py

# Atualizar dependÃªncias
uv sync --upgrade

# Verificar dependÃªncias desatualizadas
uv tree --outdated
```

